{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ntZH_CslafnW"
      },
      "outputs": [],
      "source": [
        "def clean_wikitext(line):\n",
        "  line = line.strip()\n",
        "\n",
        "  if line.startswith(\"=\") and line.endswith(\"=\"):\n",
        "    return None\n",
        "\n",
        "  line = line.replace(\"@-@\",\"-\")\n",
        "\n",
        "  line = \" \".join(line.split())\n",
        "\n",
        "  return line if len(line) > 10 else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NtaS_3hFbGDa"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/BERT/train.txt\") as f:\n",
        "  raw_lines = f.readlines()\n",
        "\n",
        "texts = []\n",
        "for line in raw_lines:\n",
        "  clean = clean_wikitext(line)\n",
        "  if clean:\n",
        "    texts.append(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqFLAB8xba0w",
        "outputId": "51810c75-879a-44e5-f025-d52389daac40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th - place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 .\n",
            "Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation zone on goal difference , before a 17 - match unbeaten run saw the team finish in seventh - place in the 24 - team 2013 – 14 Football League Two . This meant York qualified for the play - offs , and they were eliminated in the semi - final by Fleetwood Town . York were knocked out of the 2013 – 14 FA Cup , Football League Cup and Football League Trophy in their opening round matches .\n",
            "35 players made at least one appearance in nationally organised first - team competition , and there were 12 different <unk> . Defender Ben Davies missed only five of the fifty - two competitive matches played over the season . Wes Fletcher finished as leading scorer with 13 goals , of which 10 came in league competition and three came in the FA Cup . The winner of the <unk> of the Year award , voted for by the club 's supporters , was <unk> Oyebanjo .\n",
            "The 2012 – 13 season was York City 's first season back in the Football League , having won the Conference Premier play - offs in 2011 – 12 after <unk> years in the Football Conference . Manager Gary Mills was sacked in March 2013 following an 11 - match run without a victory , and was replaced by former Northern Ireland manager Nigel Worthington . Despite being in the relegation zone with three matches remaining , Worthington led the team to safety from relegation after a 1 – 0 win away to Dagenham & Redbridge on the final day of the season . York finished the season in 17th - place in the 2012 – 13 League Two table .\n",
            "Following the previous season 's conclusion Lee <unk> , Jon <unk> , Chris <unk> , Ben Everson , Scott Kerr , David <unk> , Patrick <unk> , Michael Potts , Jamie Reed and Jason Walker were released by York , while <unk> Blair departed for Fleetwood Town . David McGurk , <unk> Oyebanjo , Danny Parslow , Tom Platt and Chris Smith signed new contracts with the club . New players signed ahead of the start of the season were goalkeeper Chris <unk> on a season - long loan from Blackpool , defender Ben Davies on loan from Preston North End , midfielders Craig Clay from Chesterfield and Lewis Montrose from Gillingham , winger <unk> Puri from St <unk> and strikers Ryan Bowman from Hereford United , Richard Cresswell from Sheffield United , Wes Fletcher from Burnley and Ryan Jarvis from Torquay United . Defender Mike Atkinson and striker Chris Dickinson entered the first - team squad from the youth team after agreeing professional contracts .\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "  print(texts[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52ACv7aegp4-"
      },
      "source": [
        "#### Imports & Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hFWgZKkudfBN"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yKEyuxNsffix"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ShZ64mKzfoPe"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 30000\n",
        "SEQ_LEN = 64\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 1\n",
        "LR = 3e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vySr50rHgulX"
      },
      "source": [
        "### Simple Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qTGdKdV9fpU9"
      },
      "outputs": [],
      "source": [
        "class SimpleTokenizer:\n",
        "  def __init__(self, texts, vocab_size):\n",
        "    words = set()\n",
        "    for text in texts:\n",
        "      words.update(text.split())\n",
        "\n",
        "    words = list(words)[: vocab_size - 5]\n",
        "\n",
        "    self.word2id = {\n",
        "        \"[PAD]\":0,\n",
        "        \"[CLS]\":1,\n",
        "        \"[SEP]\":2,\n",
        "        \"[MASK]\":3,\n",
        "        \"<unk>\":4\n",
        "    }\n",
        "\n",
        "    for i, w in enumerate(words):\n",
        "      self.word2id[w] = i + 4\n",
        "\n",
        "    self.id2word = {v: k for k, v in self.word2id.items()}\n",
        "\n",
        "  def encode(self, text):\n",
        "    return [self.word2id.get(w, self.word2id[\"<unk>\"]) for w in text.split()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-L0QnL1MIpN"
      },
      "source": [
        "### MLM Dataset Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XeNzls3ajwBc"
      },
      "outputs": [],
      "source": [
        "class MLMDataset(Dataset):\n",
        "  def __init__(self, texts, tokenizer):\n",
        "    self.texts = texts\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def mask_tokens(self, tokens):\n",
        "    labels = [-100]* len(tokens)\n",
        "\n",
        "    for i in range(len(tokens)):\n",
        "      if random.random()< 0.15:\n",
        "        labels[i] = tokens[i]\n",
        "\n",
        "        prob = random.random()\n",
        "        if prob < 0.8:\n",
        "          tokens[i] = self.tokenizer.word2id[\"[MASK]\"]\n",
        "        elif prob < 0.9:\n",
        "          tokens[i] = random.randint(0, VOCAB_SIZE - 1)\n",
        "    return tokens, labels\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    tokens = self.tokenizer.encode(self.texts[idx])\n",
        "    tokens = tokens[:SEQ_LEN - 2]\n",
        "\n",
        "    tokens = (\n",
        "        [self.tokenizer.word2id[\"[CLS]\"]]\n",
        "        + tokens\n",
        "        + [self.tokenizer.word2id[\"[SEP]\"]]\n",
        "    )\n",
        "\n",
        "    tokens, labels = self.mask_tokens(tokens)\n",
        "\n",
        "    padding = SEQ_LEN - len(tokens)\n",
        "    tokens += [0] * padding\n",
        "    labels += [-100] * padding # Pad labels with ignore_index\n",
        "\n",
        "    return (\n",
        "        torch.tensor(tokens),\n",
        "        torch.tensor(labels)\n",
        "    )\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kKQsh4VaN21c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfa3612d",
        "outputId": "afc4e00c-5964-49bd-942e-fb807be78321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th - place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 .\n",
            "\n",
            "Masked tokens (numerical IDs):\n",
            " [1, 588, 20195, 6056, 7184, 10457, 20271, 5033, 7184, 10457, 14175, 7184, 8844, 21582, 1150, 22942, 10457, 21056, 5033, 3, 20615, 10515, 7184, 17755, 12001, 2693, 25678, 13613, 361, 6759, 21582, 7805, 3901, 21056, 17755, 13613, 6658, 4885, 3, 24974, 29551, 3, 6212, 15496, 1422, 7131, 3, 29169, 6056, 3, 19999, 3, 20271, 9098, 28082, 21083, 3, 21056, 20615, 19635, 3, 588, 10457, 2]\n",
            "Labels (numerical IDs, -100 for unmasked):\n",
            " [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 14140, -100, -100, -100, -100, -100, -100, 2693, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 17755, -100, -100, -100, 13613, -100, -100, 7184, -100, -100, -100, -100, 21056, -100, 6056, 7184, -100, 11676, -100, -100, -100, -100, 10457, -100, -100, -100, 29551, -100, -100, -100]\n",
            "\n",
            "--- Decoded Example ---\n",
            "Decoded Masked Sequence: [CLS] The 2013 – <unk> season was the <unk> season of <unk> times football and 77th season in the [MASK] League played <unk> York City Football Club , a professional football club based in York , North Yorkshire [MASK] England . [MASK] 17th - place finish [MASK] 2012 – [MASK] meant [MASK] was their second consecutive [MASK] in League Two [MASK] The season [SEP]\n",
            "Decoded Labels (masked words with original, unmasked words shown as is): [CLS] The 2013 – <unk> season was the <unk> season of <unk> (times -> association) football and 77th season in the ([MASK] -> Football) League played <unk> York City Football Club , a professional football club based in (York -> York) , North Yorkshire ([MASK] -> ,) England . ([MASK] -> <unk>) 17th - place finish ([MASK] -> in) 2012 (– -> –) ([MASK] -> <unk>) meant ([MASK] -> it) was their second consecutive ([MASK] -> season) in League Two ([MASK] -> .) The season [SEP]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = SimpleTokenizer(texts, VOCAB_SIZE)\n",
        "mlm_dataset = MLMDataset(texts, tokenizer)\n",
        "\n",
        "# Let's take the first item from the dataset as an example\n",
        "index_to_sample = 0\n",
        "sampled_tokens, sampled_labels = mlm_dataset[index_to_sample]\n",
        "\n",
        "# Decode tokens and labels for better understanding\n",
        "original_text = texts[index_to_sample]\n",
        "\n",
        "# To see the original tokens before masking, we'd need to re-encode the text\n",
        "# For this example, let's focus on what the dataset outputs\n",
        "\n",
        "print(f\"Original text: {original_text}\\n\")\n",
        "\n",
        "print(\"Masked tokens (numerical IDs):\\n\", sampled_tokens.tolist())\n",
        "print(\"Labels (numerical IDs, -100 for unmasked):\\n\", sampled_labels.tolist())\n",
        "\n",
        "print(\"\\n--- Decoded Example ---\")\n",
        "decoded_masked_tokens = [tokenizer.id2word.get(token_id.item(), '<unk>') for token_id in sampled_tokens]\n",
        "decoded_labels = []\n",
        "for i, label_id in enumerate(sampled_labels):\n",
        "    if label_id.item() != -100:\n",
        "        decoded_labels.append(f\"({decoded_masked_tokens[i]} -> {tokenizer.id2word.get(label_id.item(), '<unk>')})\")\n",
        "    else:\n",
        "        decoded_labels.append(tokenizer.id2word.get(sampled_tokens[i].item(), '<unk>')) # Show the unmasked token\n",
        "\n",
        "print(f\"Decoded Masked Sequence: {' '.join(decoded_masked_tokens)}\")\n",
        "print(f\"Decoded Labels (masked words with original, unmasked words shown as is): {' '.join(decoded_labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTbZGLqyHLvX"
      },
      "source": [
        "### Attention & Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7vKFfSAhQqi4"
      },
      "outputs": [],
      "source": [
        "def attention(Q, K, V):\n",
        "  scores = torch.matmul(Q, K.transpose(-2,-1))\n",
        "  scores /= math.sqrt(Q.size(-1))\n",
        "  attn = F.softmax(scores, dim=-1)\n",
        "  return torch.matmul(attn, V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNG2w6jMH9G_"
      },
      "source": [
        "### Multi-Head Self Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "E8xE5tA2H6kw"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_model, heads):\n",
        "    super().__init__()\n",
        "    self.heads = heads\n",
        "    self.d_k = d_model // heads\n",
        "\n",
        "    self.q = nn.Linear(d_model, d_model)\n",
        "    self.k = nn.Linear(d_model, d_model)\n",
        "    self.v = nn.Linear(d_model, d_model)\n",
        "    self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C  = x.shape\n",
        "\n",
        "    Q = self.q(x).view(B, T, self.heads, self.d_k).transpose(1,2)\n",
        "    K = self.q(x).view(B, T, self.heads, self.d_k).transpose(1,2)\n",
        "    V = self.q(x).view(B, T, self.heads, self.d_k).transpose(1,2)\n",
        "\n",
        "    out = attention(Q, K, V)\n",
        "    out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "    return self.out(out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RxsvxC7I2yP"
      },
      "source": [
        "### Transformer Encoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lbI4Wlf8IyPi"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, d_model, heads):\n",
        "    super().__init__()\n",
        "    self.attn = MultiHeadAttention(d_model, heads)\n",
        "    self.ff = nn.Sequential(\n",
        "        nn.Linear(d_model, 4 * d_model),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(4 * d_model, d_model)\n",
        "    )\n",
        "\n",
        "    self.norm1 = nn.LayerNorm(d_model)\n",
        "    self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.norm1(x + self.attn(x))\n",
        "    x = self.norm2(x + self.ff(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm2VgvM4JS0E"
      },
      "source": [
        "### BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "n9_TV0d1JRiX"
      },
      "outputs": [],
      "source": [
        "class MiniBERT(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model = 256, layers = 4, heads = 4):\n",
        "    super().__init__()\n",
        "\n",
        "    self.token_emb = nn.Embedding(vocab_size, d_model)\n",
        "    self.pos_emb = nn.Embedding(SEQ_LEN, d_model)\n",
        "\n",
        "    self.blocks = nn.ModuleList([\n",
        "        TransformerBlock(d_model, heads) for _ in range(layers)\n",
        "    ])\n",
        "\n",
        "    self.mlm_head = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T = x.shape\n",
        "    pos = torch.arange(T, device=x.device)\n",
        "\n",
        "    x = self.token_emb(x) + self.pos_emb(pos)\n",
        "\n",
        "    for block in self.blocks:\n",
        "      x = block(x)\n",
        "\n",
        "    return self.mlm_head(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FFIEYlnKJIH"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oWgMSmKWKCsu"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train(model, loader):\n",
        "  model.train()\n",
        "  opt = torch.optim.AdamW(model.parameters(), lr = LR)\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    # Wrap the loader with tqdm to display a progress bar\n",
        "    progress_bar = tqdm(loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
        "\n",
        "    for tokens, labels in progress_bar:\n",
        "      tokens = tokens.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      logits = model(tokens)\n",
        "      loss = F.cross_entropy(\n",
        "          logits.view(-1, VOCAB_SIZE),\n",
        "          labels.view(-1),\n",
        "          ignore_index = -100\n",
        "      )\n",
        "\n",
        "      opt.zero_grad()\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "      progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} | Loss : {total_loss/len(loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "2b5b6bc5c39e47f78043d9b5bb223a4b",
            "af362eb9c9ef4d7caeca4028d9ceef6d",
            "9346cfe4fb894921879b4bb03ce5036b",
            "b947f347871447dd84b62f22998a0b5e",
            "7dac9d7b012f40cbb05be698634ae004",
            "3715027ba53f4d149da45297c19f3d79",
            "5ef4d9924c9b4edc94ef90401a78903c",
            "2c13e791165f4919b33b16838e886d22",
            "912eebc4cb5f4ed5afdf36f04184b84d",
            "59ab0afffd714f3e83fce1b66b2c5afa",
            "330bdbdd9908406c972be288c769d1c6"
          ]
        },
        "id": "V_YF6nAJLAPM",
        "outputId": "9075b6b9-2af4-42bf-fe5a-a2559e692f65"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/1:   0%|          | 0/1085 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b5b6bc5c39e47f78043d9b5bb223a4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss : 6.5982\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  tokenizer = SimpleTokenizer(texts, VOCAB_SIZE)\n",
        "  dataset = MLMDataset(texts, tokenizer)\n",
        "  loader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True)\n",
        "\n",
        "  model = MiniBERT(VOCAB_SIZE).to(DEVICE)\n",
        "  train(model, loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd93043f"
      },
      "source": [
        "### Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88c1f62f",
        "outputId": "c5193985-84b4-48f1-cb9a-ac99520a0896"
      },
      "source": [
        "model_path = '/content/drive/MyDrive/BERT/mini_bert_model.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to mini_bert_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bba17d68"
      },
      "source": [
        "test_sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog .\",\n",
        "    \"Artificial intelligence is transforming many industries around the world .\",\n",
        "    \"Natural language processing is a subfield of artificial intelligence .\",\n",
        "    \"The sun shines brightly in the summer sky .\",\n",
        "    \"Learning deep neural networks can be challenging but rewarding .\"\n",
        "]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b1f0ea8"
      },
      "source": [
        "### Testing Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00efeec6"
      },
      "source": [
        "def predict_masked_words(text, model, tokenizer, device, seq_len, vocab_size):\n",
        "    # a. Encode the input text and truncate/pad to SEQ_LEN - 2\n",
        "    tokens = tokenizer.encode(text)\n",
        "    tokens = tokens[:seq_len - 2]\n",
        "\n",
        "    # b. Add [CLS] and [SEP] tokens\n",
        "    cls_id = tokenizer.word2id[\"[CLS]\"]\n",
        "    sep_id = tokenizer.word2id[\"[SEP]\"]\n",
        "    mask_id = tokenizer.word2id[\"[MASK]\"]\n",
        "    unk_id = tokenizer.word2id[\"<unk>\"]\n",
        "\n",
        "    full_tokens = [\n",
        "        cls_id\n",
        "    ] + tokens + [\n",
        "        sep_id\n",
        "    ]\n",
        "\n",
        "    # c. Create a masked version and keep track of original tokens for masked positions\n",
        "    masked_input_tokens = list(full_tokens)\n",
        "    labels = [-100] * len(full_tokens) # -100 for ignore_index\n",
        "\n",
        "    # Only mask non-special tokens and within the SEQ_LEN limit\n",
        "    maskable_indices = [i for i, token_id in enumerate(full_tokens) if token_id not in [cls_id, sep_id, unk_id]]\n",
        "    random.shuffle(maskable_indices)\n",
        "\n",
        "    num_masks = int(len(maskable_indices) * 0.15)\n",
        "    masked_indices = maskable_indices[:num_masks]\n",
        "\n",
        "    for i in masked_indices:\n",
        "        original_token_id = full_tokens[i]\n",
        "        labels[i] = original_token_id # Store original ID as label\n",
        "\n",
        "        prob = random.random()\n",
        "        if prob < 0.8:\n",
        "            masked_input_tokens[i] = mask_id  # 80% change to [MASK]\n",
        "        elif prob < 0.9:\n",
        "            masked_input_tokens[i] = random.randint(0, vocab_size - 1)  # 10% change to random word\n",
        "        # 10% change to keep as is (original_token_id remains in masked_input_tokens[i])\n",
        "\n",
        "    # d. Pad to SEQ_LEN\n",
        "    padding = seq_len - len(masked_input_tokens)\n",
        "    if padding > 0:\n",
        "        masked_input_tokens += [tokenizer.word2id[\"[PAD]\"]] * padding\n",
        "        labels += [-100] * padding\n",
        "    else:\n",
        "        masked_input_tokens = masked_input_tokens[:seq_len]\n",
        "        labels = labels[:seq_len]\n",
        "\n",
        "    # e. Convert to torch.tensor and move to device\n",
        "    input_tensor = torch.tensor([masked_input_tokens], device=device)\n",
        "\n",
        "    # f. Pass through the model\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)\n",
        "\n",
        "    # g. Get predicted token IDs\n",
        "    predicted_token_ids = torch.argmax(logits, dim=-1).squeeze().cpu().tolist()\n",
        "\n",
        "    # h. Decode and print results\n",
        "    decoded_masked_input = []\n",
        "    predictions_str = []\n",
        "    for i, token_id in enumerate(input_tensor.squeeze().cpu().tolist()):\n",
        "        word = tokenizer.id2word.get(token_id, '<unk>')\n",
        "        decoded_masked_input.append(word)\n",
        "        if labels[i] != -100: # If it was a masked position\n",
        "            predicted_word = tokenizer.id2word.get(predicted_token_ids[i], '<unk>')\n",
        "            predictions_str.append(f\"({word} -> {predicted_word})\")\n",
        "\n",
        "    print(f\"Original Sentence: {text}\")\n",
        "    print(f\"Masked Input: {' '.join(decoded_masked_input)}\")\n",
        "    print(f\"Predictions for Masked Words: {' '.join(predictions_str)}\")\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "792f01fd",
        "outputId": "956f6bac-f5c0-456a-de81-1abb3147c0ff"
      },
      "source": [
        "model = MiniBERT(VOCAB_SIZE).to(DEVICE)\n",
        "model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "print(\"Generating predictions for test sentences...\")\n",
        "for sentence in test_sentences:\n",
        "    predict_masked_words(sentence, model, tokenizer, DEVICE, SEQ_LEN, VOCAB_SIZE)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating predictions for test sentences...\n",
            "Original Sentence: The quick brown fox jumps over the lazy dog .\n",
            "Masked Input: [CLS] The quick [MASK] fox jumps over the <unk> <unk> . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predictions for Masked Words: ([MASK] -> <unk>)\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Sentence: Artificial intelligence is transforming many industries around the world .\n",
            "Masked Input: [CLS] Artificial intelligence [MASK] transforming many industries around the world . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predictions for Masked Words: ([MASK] -> <unk>)\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Sentence: Natural language processing is a subfield of artificial intelligence .\n",
            "Masked Input: [CLS] Natural language processing [MASK] a <unk> of artificial intelligence . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predictions for Masked Words: ([MASK] -> <unk>)\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Sentence: The sun shines brightly in the summer sky .\n",
            "Masked Input: [CLS] The sun shines [MASK] in the summer sky . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predictions for Masked Words: ([MASK] -> <unk>)\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Original Sentence: Learning deep neural networks can be challenging but rewarding .\n",
            "Masked Input: [CLS] Learning deep neural networks can murder challenging but <unk> . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Predictions for Masked Words: (murder -> ,)\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b5b6bc5c39e47f78043d9b5bb223a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af362eb9c9ef4d7caeca4028d9ceef6d",
              "IPY_MODEL_9346cfe4fb894921879b4bb03ce5036b",
              "IPY_MODEL_b947f347871447dd84b62f22998a0b5e"
            ],
            "layout": "IPY_MODEL_7dac9d7b012f40cbb05be698634ae004"
          }
        },
        "af362eb9c9ef4d7caeca4028d9ceef6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3715027ba53f4d149da45297c19f3d79",
            "placeholder": "​",
            "style": "IPY_MODEL_5ef4d9924c9b4edc94ef90401a78903c",
            "value": "Epoch 1/1: 100%"
          }
        },
        "9346cfe4fb894921879b4bb03ce5036b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c13e791165f4919b33b16838e886d22",
            "max": 1085,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_912eebc4cb5f4ed5afdf36f04184b84d",
            "value": 1085
          }
        },
        "b947f347871447dd84b62f22998a0b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59ab0afffd714f3e83fce1b66b2c5afa",
            "placeholder": "​",
            "style": "IPY_MODEL_330bdbdd9908406c972be288c769d1c6",
            "value": " 1085/1085 [32:17&lt;00:00,  1.52s/it, loss=6.38]"
          }
        },
        "7dac9d7b012f40cbb05be698634ae004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3715027ba53f4d149da45297c19f3d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef4d9924c9b4edc94ef90401a78903c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c13e791165f4919b33b16838e886d22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "912eebc4cb5f4ed5afdf36f04184b84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59ab0afffd714f3e83fce1b66b2c5afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "330bdbdd9908406c972be288c769d1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}